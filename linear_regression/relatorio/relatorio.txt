# Pre-processamento

Identificacao de colunas categóricas:
MSSub Class
MSZoning
Street
Alley
LotShape
LandContour
Utilities
Lot Config
Land Slope
Neighborhood
Condition1
Condition2
Bldg Type
HouseStyle
RoofStyle
RoofMatl
Exterior1st
Exterior2nd
MasVnrType
MasVnrArea
Foundation
Heating
HeatingQC
CentralAir
Electrical
Functional
GarageType
MiscFeature
SaleType

Identificação de colunas ordinais:
OverallQual
OverallCond
YearBuilt
YearRemodAdd
ExterQual
ExterCond
BsmtQual (para as colunas Bsmt, é interessante notar que TotalBsmtSF = 0 indica que não há porão)
BsmtCond
BsmtExposure
BsmtFinType1
BsmtFinType2
KitchenQual
FireplaceQu
GarageYrBlt
GarageFinish
GarageQual
GarageCond
PavedDrive
PoolQC
Fence
MoSold
YrSold
SaleCondition

Preparação dos dados:

1 - As colunas ordinais foram processadas através do módulo category_encoders.ordinal.OrdinalEncoder, de modo que a ordenação semântica seja mantida.
2 - As colunas categóricas foram convertidas para números através do módulo sklearn.preprocessing.LabelEncoder
3 - Algumas colunas foram removidas arbitrariamente, por se tratarem de categorias, na minha opinião, subjetivas demais.
    São elas: ["BsmtFinType1", "BsmtFinType2", "GarageFinish", "GarageQual", "GarageCond", "PavedDrive"]
4 - Ao tentar carregar os dados de teste, separadamente dos dados de treinamento, houve erros devido a novas categorias.
Resolvi copiar a lista exaustiva do arquivo `data_description.txt` e formatá-la em um arquivo. Para isso:
    a) O comando `awk '{print $1}' data_description.txt > easier.txt` mais expressões regulares e o editor de texto Visual Studio Code facilitaram o trabalho.
    b) Expressões regulares também foram utilizadas para corrigir typos e informações faltantes nos dados de treinamento e de teste, evitando edição manual.

Treinamento:

1 - Como linha de base, escolhi treinar o regressor SVM padrão.
O resultado obtido no Kaggle foi: 0.41885 (submission1.png)
2 - Depois, para experimentar com escala, mudei para o StandardScaler + SVM (submission2.png)
3 - A terceira tentativa foi com o RidgeCV + StandardScaler, alphas de [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50] (submission3.png)
4 - A quarta tentativa utilizou grid search com cross-validation sobre um regressor SVM ('SVM_GRID'):
    grid: {
        'C': [1e0, 1e1, 1e2, 1e3],
        'kernel': ['linear', 'rbf']
    }
    O melhor estimador foi: regressor.regressor.best_estimator_ == SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto', kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
    Nesta tentativa, houve uma melhora considerável, que me fez avançar 1605 posições no leaderboard (submission4.png)
5 - Agora, resolvi experimentar com uma malha de busca mais complexa:
    grid: {
        'C': [1e0, 5e0, 1e1, 5e1, 1e2, 5e2, 1e3],
        'epsilon': [1e-3, 1e-2, 1e-1, 1e0],
        'kernel': ['linear', 'rbf', 'poly'],
        'degree': [2, 3, 4]
    }
    O melhor estimador foi: SVR(C=50.0, cache_size=200, coef0=0.0, degree=2, epsilon=1.0, gamma='auto',
  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)